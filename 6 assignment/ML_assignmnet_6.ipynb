{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gBZhRIblMeUB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.board = np.zeros((3, 3))\n",
        "        self.current_player = 1\n",
        "\n",
        "    def reset(self):\n",
        "        self.board.fill(0)\n",
        "        self.current_player = 1\n",
        "        return self.board\n",
        "\n",
        "    def available_moves(self):\n",
        "        return np.argwhere(self.board == 0)\n",
        "\n",
        "    def make_move(self, row, col):\n",
        "        if self.board[row, col] == 0:\n",
        "            self.board[row, col] = self.current_player\n",
        "            self.current_player *= -1\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def check_winner(self):\n",
        "        for player in [1, -1]:\n",
        "            if (np.any(np.all(self.board == player, axis=0)) or\n",
        "                np.any(np.all(self.board == player, axis=1)) or\n",
        "                np.all(np.diag(self.board) == player) or\n",
        "                np.all(np.diag(np.fliplr(self.board)) == player)):\n",
        "                return player\n",
        "        if np.all(self.board != 0):\n",
        "            return 0\n",
        "        return None\n",
        "\n",
        "    def render(self):\n",
        "        print(self.board)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kNteMAodMfM_"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, learning_rate=0.1, discount_factor=0.9, exploration_rate=1.0, exploration_decay=0.99):\n",
        "        self.q_table = {}\n",
        "        self.learning_rate = learning_rate\n",
        "        self.discount_factor = discount_factor\n",
        "        self.exploration_rate = exploration_rate\n",
        "        self.exploration_decay = exploration_decay\n",
        "\n",
        "    def get_state_key(self, state):\n",
        "        return str(state)\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        state_key = self.get_state_key(state)\n",
        "        if state_key not in self.q_table:\n",
        "            self.q_table[state_key] = np.zeros(9)\n",
        "\n",
        "        if random.uniform(0, 1) < self.exploration_rate:\n",
        "            return random.choice(np.argwhere(state.flatten() == 0).flatten())\n",
        "        else:\n",
        "            return np.argmax(self.q_table[state_key])\n",
        "\n",
        "    def learn(self, state, action, reward, next_state):\n",
        "        state_key = self.get_state_key(state)\n",
        "        next_state_key = self.get_state_key(next_state)\n",
        "\n",
        "        if next_state_key not in self.q_table:\n",
        "            self.q_table[next_state_key] = np.zeros(9)\n",
        "\n",
        "        q_predict = self.q_table[state_key][action]\n",
        "        q_target = reward + self.discount_factor * np.max(self.q_table[next_state_key])\n",
        "\n",
        "        self.q_table[state_key][action] += self.learning_rate * (q_target - q_predict)\n",
        "\n",
        "    def decay_exploration(self):\n",
        "        self.exploration_rate *= self.exploration_decay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qeLjSY6KMoOL"
      },
      "outputs": [],
      "source": [
        "def train_agent(episodes):\n",
        "    env = TicTacToe()\n",
        "    agent = QLearningAgent()\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = agent.choose_action(state)\n",
        "            row, col = divmod(action, 3)\n",
        "\n",
        "            if env.make_move(row, col):\n",
        "                winner = env.check_winner()\n",
        "                if winner is not None:\n",
        "                    reward = 1 if winner == 1 else -1 if winner == -1 else 0\n",
        "                    agent.learn(state, action, reward, state)\n",
        "                    done = True\n",
        "                else:\n",
        "                    next_state = state\n",
        "                    agent.learn(state, action, 0, next_state)\n",
        "                    state = next_state\n",
        "\n",
        "        agent.decay_exploration()\n",
        "        if episode % 100 == 0:\n",
        "            print(f'Episode {episode}, Exploration Rate: {agent.exploration_rate:.3f}')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ35lUhpx7y0",
        "outputId": "4fd4e5b0-8c18-4858-b9e3-531789e89e45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0, Exploration Rate: 0.990\n",
            "Episode 100, Exploration Rate: 0.362\n",
            "Episode 200, Exploration Rate: 0.133\n",
            "Episode 300, Exploration Rate: 0.049\n",
            "Episode 400, Exploration Rate: 0.018\n",
            "Episode 500, Exploration Rate: 0.007\n",
            "Episode 600, Exploration Rate: 0.002\n",
            "Episode 700, Exploration Rate: 0.001\n",
            "Episode 800, Exploration Rate: 0.000\n",
            "Episode 900, Exploration Rate: 0.000\n",
            "[[0. 1. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[ 0.  1. -1.]\n",
            " [ 0.  0.  0.]\n",
            " [ 0.  0.  0.]]\n",
            "[[ 0.  1. -1.]\n",
            " [ 0.  1.  0.]\n",
            " [ 0.  0.  0.]]\n",
            "[[ 0.  1. -1.]\n",
            " [ 0.  1.  0.]\n",
            " [ 0.  0. -1.]]\n",
            "[[ 0.  1. -1.]\n",
            " [ 1.  1.  0.]\n",
            " [ 0.  0. -1.]]\n",
            "[[ 0.  1. -1.]\n",
            " [ 1.  1.  0.]\n",
            " [-1.  0. -1.]]\n",
            "[[ 0.  1. -1.]\n",
            " [ 1.  1.  0.]\n",
            " [-1.  1. -1.]]\n",
            "Winner: Player 1\n"
          ]
        }
      ],
      "source": [
        "def test_agent(agent):\n",
        "    env = TicTacToe()  \n",
        "    state = env.reset() \n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "      \n",
        "        action = agent.choose_action(state)\n",
        "        row, col = divmod(action, 3)\n",
        "\n",
        "        if env.make_move(row, col): \n",
        "            env.render() \n",
        "            winner = env.check_winner()  \n",
        "            if winner is not None:  \n",
        "                print(f\"Winner: {'Player 1' if winner == 1 else 'Player 2' if winner == -1 else 'Draw'}\")\n",
        "                done = True\n",
        "            else:\n",
        "                available_moves = env.available_moves()\n",
        "                if available_moves.size > 0:\n",
        "                    opponent_action = random.choice(available_moves)\n",
        "                    env.make_move(opponent_action[0], opponent_action[1])\n",
        "                env.render()\n",
        "                winner = env.check_winner()\n",
        "                if winner is not None:\n",
        "                    print(f\"Winner: {'Player 1' if winner == 1 else 'Player 2' if winner == -1 else 'Draw'}\")\n",
        "                    done = True\n",
        "\n",
        "agent = QLearningAgent()  \n",
        "train_agent(1000)  \n",
        "test_agent(agent)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbtZ50M1aa-w"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
