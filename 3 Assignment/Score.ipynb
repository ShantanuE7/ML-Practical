{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Frequenceies"
      ],
      "metadata": {
        "id": "flPcigi6qpUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOgXF48zsrwm",
        "outputId": "112b1a80-713b-4ac7-fedf-b2cb20b36a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUXY4AKNlA7v",
        "outputId": "c1f526a9-02a8-4022-c7f1-764584180608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingredient frequencies saved to /content/ingredient_freq.csv\n",
            "Co-occurrence frequencies saved to /content/co_occurrence_freq.csv\n"
          ]
        }
      ],
      "source": [
        "#code for saving the frequencies\n",
        "\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import csv\n",
        "\n",
        "# Step 1: Load and preprocess the recipe data\n",
        "def load_recipes(filepath):\n",
        "    return pd.read_csv(filepath)\n",
        "\n",
        "# Step 2: Calculate occurrence and co-occurrence frequencies\n",
        "def calculate_occurrence(recipes):\n",
        "    ingredient_freq = defaultdict(int)\n",
        "    for recipe in recipes['ingredients']:\n",
        "        ingredients = recipe.split(\", \")\n",
        "        for ingredient in ingredients:\n",
        "            ingredient_freq[ingredient] += 1\n",
        "    return ingredient_freq\n",
        "\n",
        "def calculate_cooccurrence(recipes):\n",
        "    co_occurrence_freq = defaultdict(int)\n",
        "    for recipe in recipes['ingredients']:\n",
        "        ingredients = recipe.split(\", \")\n",
        "        for i, ing1 in enumerate(ingredients):\n",
        "            for ing2 in ingredients[i+1:]:\n",
        "                pair = tuple(sorted([ing1, ing2]))\n",
        "                co_occurrence_freq[pair] += 1\n",
        "    return co_occurrence_freq\n",
        "\n",
        "# Step 4: Save ingredient frequencies to CSV\n",
        "def save_ingredient_freq(ingredient_freq, filepath):\n",
        "    with open(filepath, 'w', newline='') as outfile:\n",
        "        writer = csv.writer(outfile)\n",
        "        writer.writerow(['Ingredient', 'Frequency'])\n",
        "        for ingredient, freq in ingredient_freq.items():\n",
        "            writer.writerow([ingredient, freq])\n",
        "\n",
        "# Step 5: Save co-occurrence frequencies to CSV\n",
        "def save_cooccurrence_freq(co_occurrence_freq, filepath):\n",
        "    with open(filepath, 'w', newline='') as outfile:\n",
        "        writer = csv.writer(outfile)\n",
        "        writer.writerow(['Ingredient Pair', 'Frequency'])\n",
        "        for pair, freq in co_occurrence_freq.items():\n",
        "            writer.writerow([f\"{pair[0]}, {pair[1]}\", freq])\n",
        "\n",
        "# Step 7: Test the system with a sample recipe\n",
        "recipes = load_recipes(\"/content/final_data5000.csv\")\n",
        "\n",
        "\n",
        "ingredient_freq = calculate_occurrence(recipes)\n",
        "save_ingredient_freq(ingredient_freq, \"/content/ingredient_freq.csv\")\n",
        "print(\"Ingredient frequencies saved to /content/ingredient_freq.csv\")\n",
        "\n",
        "co_occurrence_freq = calculate_cooccurrence(recipes)\n",
        "save_cooccurrence_freq(co_occurrence_freq, \"/content/co_occurrence_freq.csv\")\n",
        "print(\"Co-occurrence frequencies saved to /content/co_occurrence_freq.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extracting Unique elements"
      ],
      "metadata": {
        "id": "5_qFHH31rMv0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxoO3UrolqzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf57f4b-1ec2-4060-9244-e73dc28386d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/project/Copy of Totally_cleaned_dataset_10000.csv'\n",
        "recipes_df = pd.read_csv(file_path)\n",
        "\n",
        "# Extract all ingredients from the \"ingredients\" column\n",
        "all_ingredients = set()\n",
        "\n",
        "for recipe in recipes_df['ingredients']:\n",
        "    ingredients = recipe.split(\", \")  # Assuming ingredients are separated by commas\n",
        "    all_ingredients.update(ingredients)\n",
        "\n",
        "# Convert the set of ingredients to a DataFrame\n",
        "ingredients_df = pd.DataFrame(list(all_ingredients), columns=['ingredient'])\n",
        "\n",
        "# Save the DataFrame to a new CSV file\n",
        "output_file_path = '/content/unique_ingredients.csv'\n",
        "ingredients_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "# Print the path to the saved file\n",
        "print(f\"Unique ingredients saved to {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb_Obx3GrABi",
        "outputId": "40ef2df0-4f33-4bfb-c711-d36a73e5d8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique ingredients saved to /content/unique_ingredients.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ingredient: Category"
      ],
      "metadata": {
        "id": "YYgSh592rRWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = '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'\n",
        "\n",
        "def classify_ingredient(ingredient):\n",
        "    # Define the categories\n",
        "    categories = [\"vegetable\", \"fruit\", \"spice\", \"herb\", \"grain\", \"dairy\", \"protein\", \"sweetener\"]\n",
        "\n",
        "    # Create the prompt\n",
        "    prompt = (f\"Classify the following ingredient into one of these categories: {', '.join(categories)}.\\n\"\n",
        "              f\"Ingredient: {ingredient}\\n\"\n",
        "              f\"Category:\")\n",
        "\n",
        "    # Make the API call\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",  # Use gpt-3.5-turbo model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=10,\n",
        "        temperature=0.3\n",
        "    )\n",
        "\n",
        "    # Extract and return the category\n",
        "    category = response.choices[0].message['content'].strip()\n",
        "    return category\n",
        "\n",
        "def classify_ingredients_in_csv(input_csv, output_csv):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    # Ensure there's a column for ingredients\n",
        "    if 'ingredient' not in df.columns:\n",
        "        raise ValueError(\"CSV file must contain an 'ingredient' column\")\n",
        "\n",
        "    # Classify each ingredient\n",
        "    df['category'] = df['ingredient'].apply(classify_ingredient)\n",
        "\n",
        "    # Save the results to a new CSV file\n",
        "    df.to_csv(output_csv, index=False)\n",
        "\n",
        "# Example usage\n",
        "input_csv = '/content/unique_ingredients.csv'\n",
        "output_csv = 'classified_ingredients.csv'\n",
        "classify_ingredients_in_csv(input_csv, output_csv)\n"
      ],
      "metadata": {
        "id": "EXfdiUl0rEVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Category AS a column"
      ],
      "metadata": {
        "id": "9VIRHo77rVvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your CSV file\n",
        "df = pd.read_csv('/content/classified_ingredients.csv')\n",
        "\n",
        "# Create a pivot table where categories are columns and ingredients are values\n",
        "pivot_df = df.groupby('category')['ingredient'].apply(lambda x: ', '.join(x)).reset_index()\n",
        "\n",
        "# Split the concatenated string of ingredients into separate rows\n",
        "expanded_df = pivot_df.set_index('category')['ingredient'].str.split(', ', expand=True).T\n",
        "\n",
        "# Save the result as a CSV file\n",
        "expanded_df.to_csv('/content/categorized data.csv', index=False)\n",
        "\n",
        "print(\"Transformed data has been saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyB0JrIYrG4x",
        "outputId": "db2be3e4-5755-4280-ca90-e42f257c54dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed data has been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BCTPcc9HvjM6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}